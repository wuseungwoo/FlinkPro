基于Flink构建流批一体化实时数据仓库:
基于Flink SQL/CDC 的扩展工作，构建实时数仓的应用案例.由于缺乏Flink SQL IDE所以是通过
jar包来实现Flink SQL提交实时任务;

简述离线数仓的缺点,引入为什么要做实时数仓:
我们主要是由于以下两点决定构建实时数仓:
1.业务方面:
    实时报表:
    实时标签:
    实时接口:

2.平台方面:
    调度任务:凌晨0点大批量启动
    标签导入:全量导入耗费数小时
    质量监控:及时发现数据问题

如何从已有的离线数仓平滑迁移到实时数仓呢?
构建流批一体式数仓:
方案对比                lambda架构            Kappa架构         实际需求

实时性:                T+1的宽表/T+0的实时表   T+0的实时表        T+0的实时宽表
资源消耗:              流批同时运行,资源消耗大  纯流处理,资源消耗小  大部分流处理资源消耗一般
更新历史数据:           全量更新计算            全量更新计算       直接更新源表,保留更新记录
重新计算时吞吐:         全量批处理,吞吐量大      全量流处理,吞吐量较批处理小 无需重新计算
实用性:                全场景                 部分场景           全场将

Flink运行模式:
Flink on Yarn / K8s
Flink集群规模:

Flink作业管理:?
目前作业提交在没有SQL IDE的前提下:
    1.Flink jar包提交运行
    2.Flink SQL Client(不可投入生产)
    3.较大的公司会提供sql作业提交的可视化界面:
        阿里巴巴的Flink 实时作业SQL全托管
        袋鼠云的Flink SQL的作业提交可视化界面
        360的奥创SQL提交应用
Flink集群部署:flink on yarn/yarn-per-job模式

技术选型:
Flink SQL+UDF - kafka(数据存储)

为什么选择Flink SQL作为实时数仓的技术选型?
    1.开发复杂度高,管理成本高
    Flink Job的API使用复杂,需要对Flink非常深入的理解
    maven项目构建不够约束,Job jar对于平台来讲是一个黑河,难以规范和约束

    2.实时数据没有数仓化
    数据没有schema规范,没有元数据管理
    缺乏对数据的分层和模型约束
    烟囱式开发重复抵消的使用
    没有很好的权限控制,没有项目规划,只是Flink集群和做作业管理的基本管理
    没有打通与数据的联系,如数据地图,数据血缘,任务依赖

    3.实时离线不统一
    离线是Hive数仓式管理,实时是API式的开发
    实时架构和离线架构不统一,需要梳理两套架构,重复两套开发逻辑

实时批流一体化实现了一套SQL实时离线共用;
故此,构建实时离线流批一体化数仓成为了数仓进化之路的关键;

Lambda架构:
数据源->kafka(原始表)->Flink(流式处理)->kafka(明细表->流式即席查询)+Hbase/Redis(维度表)->
kafka(汇总表)->Mysql/Presto+SmartBI(报表分析)->ES(用户画像/实时标签)->Redis/Hbase(接口服务)


流批一体架构(有图):
业务数据库->Flink CDC->kafka->Flink SQL->kafka->Flink SQL->Flink SQL Connector

OLAP数据服务:(Druid+Presto)

为什么使用Flink SQL,或者你觉得Flink SQL的优点是什么?
1.最底层的process function:
    1.低延迟,高吞吐
    2.高容错状态
    3.端到端的Exactly-once
    4.Window函数&Event time&Watermark

2.最上层的Table&SQL:
    1.ANSI SQL+UDF
    2.支持丰富的数据类型+内置函数
    3.自定义Source/Sink
    4.批流统一

基本日常代码范例:
    参考下方教程:
    1.注册数据源表
    2.注册数据输出表
    3.注册UDF函数
    4.编写清洗SQL

Flink实时数仓的构建思路分块(有图):
权限:
血缘:
质量:

SQL/UDF:
统一Hive UDF管理:
    Flink跟Hive集成,通过Hive Module,Hive UDF可以直接被Flink SQL使用
    Hive UDF jar统一存储在HDFS
    Hive UDF注册持久化到 Hive metastore
    实时数仓在flink_rtdw,离线数仓在 hive_edw

    查看UDF,进入Hive metastore:show function

Flink可以直接使用在Hive中注册的UDF函数;使用Hive的UDF函数时间上全局可用.
当然你也可以注册只在Flink中使用的UDF,但是过于激进;


层次,主题,schema:

->  一切的数据资产均视为表
    一切的ETL job均SQL化
    统一数仓化管理
    开发流程统一
    用户体验一致;

你在项目中主要负责哪个部分?



在项目开发中遇到了哪些问题?什么原因?如何解决?



如果项目中使用了lambda架构的话,你的实时部分和离线部分可能是基于两套代码开发.
就实时部分的data stream API来讲使用过程中可能会遇到一些问题:
腾讯在flink datastream API使用中遇到的问题:https://www.bilibili.com/video/BV1W54y1x7XZ?p=11&spm_id_from=pageDriver


你在项目中做了哪些优化?


做完这个项目你学到了什么?并对当前项目的发展做了哪些思考和展望?
#可不可能自己去开发更加丰富的Flink SQL Connector?
#可以去探索基于Iceberg的Flink实时数仓,构建湖仓一体化,即为:数据湖和实时数仓的一体化?
#构建更加易于开发的Flink SQL作业提交方式和IDE?




















































































































































































































































































































































































































































































































































































































































































































































































